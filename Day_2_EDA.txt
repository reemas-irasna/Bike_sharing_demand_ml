# <b><u> Project Title : Seoul Bike Sharing Demand Prediction </u></b>

## <b> Problem Description </b>

### Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes.


## <b> Data Description </b>

### <b> The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.</b>


### <b>Attribute Information: </b>

* ### Date : year-month-day
* ### Rented Bike count - Count of bikes rented at each hour
* ### Hour - Hour of he day
* ### Temperature-Temperature in Celsius
* ### Humidity - %
* ### Windspeed - m/s
* ### Visibility - 10m
* ### Dew point temperature - Celsius
* ### Solar radiation - MJ/m2
* ### Rainfall - mm
* ### Snowfall - cm
* ### Seasons - Winter, Spring, Summer, Autumn
* ### Holiday - Holiday/No holiday
* ### Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)

import numpy as np
import pandas as pd
from numpy import math

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error, mean_absolute_error
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
from sklearn.tree import DecisionTreeClassifier

data = pd.read_csv('/content/drive/MyDrive/Data/SeoulBikeData.csv', encoding= 'unicode_escape')

from google.colab import drive
drive.mount('/content/drive')

data.head()

data.describe(include='all')

data.describe()

data.info()

#check for duplicates
len(data[data.duplicated()])

#data distribution for target variable
plt.figure(figsize=(9,8))
sns.distplot(data['Rented Bike Count'],color="r")

# square_root transformation
plt.figure(figsize=(10,8))
sns.distplot(np.sqrt(data['Rented Bike Count']),color="r")

data_new = data.copy()

#feature engg to covert days in numeric
days= {'Sunday':7,'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6}

def get_days(x):
  return days[x]



#Date columns to Date format conversion
data_new['Date']= pd.to_datetime(data_new['Date'])

# extracting day,month, day of week and weekdays/weekend from date column
data_new['Date']=pd.to_datetime(data_new['Date'])
data_new['month'] = data_new['Date'].apply(lambda x : x.month)
data_new['day_of_week'] = data_new['Date'].dt.day_name()



data_new['weekdays_weekend']=data_new['day_of_week'].apply(lambda x : get_days(x))

data_new=data_new.drop(columns=['Date','day_of_week'],axis=1)

data_new.head()

data_new['weekdays_weekend'].unique()

data_new['month'].unique()

continous_features = ['Temperature(°C)', 'Humidity(%)', 'Wind speed (m/s)', 'Visibility (10m)', 'Dew point temperature(°C)', 'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)']
continous_features

data_new.info()

for col in continous_features:
    fig = plt.figure(figsize=(9, 6))
    ax = fig.gca()
    continous_feature = data_new[col]
    continous_feature.hist(bins=50, ax = ax)
    ax.axvline(continous_feature.mean(), color='magenta', linestyle='dashed', linewidth=2)
    ax.axvline(continous_feature.median(), color='cyan', linestyle='dashed', linewidth=2)    
    ax.set_title(col)
plt.show()

for col in continous_features:
    fig = plt.figure(figsize=(9, 6))
    ax = fig.gca()
    continous_feature = np.sqrt(data_new[col])
    continous_feature.hist(bins=50, ax = ax)
    ax.axvline(continous_feature.mean(), color='magenta', linestyle='dashed', linewidth=2)
    ax.axvline(continous_feature.median(), color='cyan', linestyle='dashed', linewidth=2)    
    ax.set_title(col)
plt.show()

for col in continous_features:
    fig = plt.figure(figsize=(9, 6))
    ax = fig.gca()
    continous_feature = data_new[col]
    label = data_new['Rented Bike Count']
    correlation = continous_feature.corr(label)
    plt.scatter(x=continous_feature, y=label)
    plt.xlabel(col)
    plt.ylabel('Rented Bike Count')
    ax.set_title('Rented Bike Count vs ' + col + '- correlation: ' + str(correlation))
    z = np.polyfit(data_new[col], data_new['Rented Bike Count'], 1)
    y_hat = np.poly1d(z)(data_new[col])

    plt.plot(data_new[col], y_hat, "r--", lw=1)

plt.show()

#ploting line graph
# group by Hrs and get average Bikes rented, and precent change
avg_rent_hrs = data_new.groupby('Hour')['Rented Bike Count'].mean()

# plot average rent over time(hrs)
plt.figure(figsize=(20,4))
a=avg_rent_hrs.plot(legend=True,marker='o',title="Average Bikes Rented Per Hr")
a.set_xticks(range(len(avg_rent_hrs)));
a.set_xticklabels(avg_rent_hrs.index.tolist(), rotation=85);

sns.catplot(x='Seasons',y='Rented Bike Count',data=data_new, size=8)

plt.figure(figsize=(15,8))
correlation = data_new.corr()
sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')

data_new['temperature'] = 0.5*data_new['Temperature(°C)'] + 0.5*data_new['Dew point temperature(°C)']

from statsmodels.stats.outliers_influence import variance_inflation_factor
def calc_vif(X):

    # Calculating VIF
    vif = pd.DataFrame()
    vif["variables"] = X.columns
    vif["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

    return(vif)

continous_feature_df = pd.DataFrame(data_new[continous_features])


continous_feature_df

calc_vif(data_new[[i for i in continous_feature_df]])

calc_vif(data_new[[i for i in continous_feature_df if i not in ['Dew point temperature(°C)','Temperature(°C)']]])

data_new.columns

categorical_features = ['Hour','Seasons','Holiday','Functioning Day', 'month', 'weekdays_weekend']

categorical_features_df= pd.DataFrame(data_new[categorical_features])

categorical_features_df.head()

for col in categorical_features:
    counts = data_new[col].value_counts().sort_index()
    fig = plt.figure(figsize=(9, 6))
    ax = fig.gca()
    counts.plot.bar(ax = ax, color='steelblue')
    ax.set_title(col + ' counts')
    ax.set_xlabel(col) 
    ax.set_ylabel("Frequency")
plt.show()

for col in categorical_features:
    fig = plt.figure(figsize=(9, 6))
    ax = fig.gca()
    data_new.boxplot(column = 'Rented Bike Count', by = col, ax = ax)
    ax.set_title('Label by ' + col)
    ax.set_ylabel("Rented Bike Count")
plt.show()

data_new.head()

data_new['Holiday'] = data_new['Holiday'].apply(lambda x : 1 if x == 'Holiday' else 0)

data_new['Functioning Day'] = data_new['Functioning Day'].apply(lambda x : 1 if x == 'Yes' else 0)

data_new = pd.get_dummies(data_new, columns=["Seasons"], prefix=["seasond"])

categorical_features = ['Hour','Holiday','Functioning Day', 'month', 'weekdays_weekend', 'seasond_Autumn', 'seasond_Spring', 'seasond_Summer', 'seasond_Winter']

continous_final_features = ['Humidity(%)', 'Wind speed (m/s)', 'Visibility (10m)', 'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)', 'temperature']
categorical_final_features = ['Hour','Holiday','Functioning Day', 'month', 'weekdays_weekend', 'seasond_Autumn', 'seasond_Spring', 'seasond_Summer', 'seasond_Winter']

final_features = continous_final_features + categorical_final_features
final_features

len(final_features)

from scipy.stats import zscore
#Train test split
X = data_new[final_features].apply(zscore)

y = np.sqrt(data_new['Rented Bike Count'])

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)


print(X_train.shape)
print(X_test.shape)

#linear Regression
from sklearn.linear_model import LinearRegression

reg = LinearRegression().fit(X_train, y_train)

reg.score(X_train, y_train)

reg.coef_

reg.intercept_

y_pred = reg.predict(X_test)

print(y_pred)

from sklearn.metrics import mean_squared_error

MSE  = mean_squared_error((y_test)**2, (y_pred)**2)
print("MSE :" , MSE)

RMSE = np.sqrt(MSE)
print("RMSE :" ,RMSE)

from sklearn.metrics import r2_score
r2 = r2_score((y_test)**2, (y_pred)**2)
print("R2 :" ,r2)
print("Adjusted R2 : ",1-(1-r2_score((y_test)**2, (y_pred)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))

plt.figure(figsize=(15,12))
plt.plot((y_pred[:100])**2)
plt.plot(np.array((y_test[:100])**2))
plt.legend(["Predicted","Actual"])
plt.show()

## Lasso


from sklearn.linear_model import Lasso
lasso  = Lasso(alpha=0.005)

lasso.fit(X_train, y_train)

lasso.score(X_train, y_train)

lasso.coef_

## Lasso using CV


# finding the best parameters for lasso by gridsearchcv
from sklearn.model_selection import GridSearchCV
lasso_model = Lasso()
#setting the parameters of the lasso model
parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100,0.0014]}
lasso_grid = GridSearchCV(lasso_model, parameters, scoring='neg_mean_squared_error', cv=5)

print("The best fit alpha value is found out to be :" ,lasso_grid.best_params_)
print("\nUsing ",lasso_grid.best_params_, " the negative mean squared error is: ", lasso_grid.best_score_)

lasso_cv = lasso_grid.fit(X_train, y_train)

lasso_pred =lasso_grid.predict(X_test)

MSE = mean_squared_error(y_test**2,lasso_pred**2)
print("MSE :" , MSE)

RMSE = np.sqrt(MSE)
print("RMSE :" ,RMSE)

  #finding the r2 score
r2 = r2_score(y_test**2,lasso_pred**2)
print("R2 :" ,r2)
  #finding the adjusted r2 score
adj_r2=1-(1-r2_score(y_test**2,lasso_pred**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))
print("Adjusted R2 : ",adj_r2)

plt.figure(figsize=(15,12))
plt.plot((lasso_pred[:100])**2)
plt.plot(np.array((y_test[:100])**2))
plt.legend(["Predicted","Actual"])
plt.show()

## Ridge


from sklearn.linear_model import Ridge
ridge = Ridge()
parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}
ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=5)
ridge_regressor.fit(X_train,y_train)

print("The best fit alpha value is found out to be :" ,ridge_regressor.best_params_)
print("\nUsing ",ridge_regressor.best_params_, " the negative mean squared error is: ", ridge_regressor.best_score_)

y_pred_ridge = ridge_regressor.predict(X_test)

MSE  = mean_squared_error((y_test)**2, (y_pred_ridge)**2)
print("MSE :" , MSE)

RMSE = np.sqrt(MSE)
print("RMSE :" ,RMSE)

r2 = r2_score((y_test)**2, (y_pred_ridge)**2)
print("R2 :" ,r2)
print("Adjusted R2 : ",1-(1-r2_score((y_test)**2, (y_pred_ridge)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))

plt.figure(figsize=(15,12))
plt.plot((y_pred_ridge[:100])**2)
plt.plot(np.array((y_test[:100])**2))
plt.legend(["Predicted","Actual"])
plt.show()

## ElasticNet


from sklearn.linear_model import ElasticNet
#a * L1 + b * L2
#alpha = a + b and l1_ratio = a / (a + b)
elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.5)

elasticnet.fit(X_train,y_train)

elasticnet.score(X_train, y_train)

y_pred_en = elasticnet.predict(X_test)

MSE  = mean_squared_error((y_test)**2, (y_pred_en)**2)
print("MSE :" , MSE)

RMSE = np.sqrt(MSE)
print("RMSE :" ,RMSE)

r2 = r2_score((y_test)**2, (y_pred_en)**2)
print("R2 :" ,r2)
print("Adjusted R2 : ",1-(1-r2_score((y_test)**2, (y_pred_en)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))

plt.figure(figsize=(15,12))
plt.plot((y_pred_en[:100])**2)
plt.plot(np.array((y_test[:100])**2))
plt.legend(["Predicted","Actual"])
plt.show()

elastic = ElasticNet()
parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100],'l1_ratio':[0.3,0.4,0.5,0.6,0.7,0.8]}
elastic_regressor = GridSearchCV(elastic, parameters, scoring='neg_mean_squared_error',cv=5)
elastic_regressor.fit(X_train, y_train)

print("The best fit alpha value is found out to be :" ,elastic_regressor.best_params_)
print("\nUsing ",elastic_regressor.best_params_, " the negative mean squared error is: ", elastic_regressor.best_score_)

y_pred_elastic = elastic_regressor.predict(X_test)

MSE  = mean_squared_error((y_test)**2, (y_pred_elastic)**2)
print("MSE :" , MSE)

RMSE = np.sqrt(MSE)
print("RMSE :" ,RMSE)

r2 = r2_score((y_test)**2, (y_pred_elastic)**2)
print("R2 :" ,r2)
print("Adjusted R2 : ",1-(1-r2_score((y_test)**2, (y_pred_elastic)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))

plt.figure(figsize=(15,12))
plt.plot((y_pred_elastic[:100])**2)
plt.plot(np.array((y_test[:100])**2))
plt.legend(["Predicted","Actual"])
plt.show()

## Descision trees

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score
regeressor = DecisionTreeRegressor(random_state = 100)
regeressor.fit(X_train,y_train)

y_pred_dt = regeressor.predict(X_test)

# Metrics for Decision Tree
MSE  = mean_squared_error((y_test)**2, (y_pred_dt)**2)
print("MSE :" , MSE)

RMSE = np.sqrt(MSE)
print("RMSE :" ,RMSE)

r2 = r2_score((y_test)**2, (y_pred_dt)**2)
print("R2 :" ,r2)
print("Adjusted R2 : ",1-(1-r2_score((y_test)**2, (y_pred_dt)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))

y_test[:5]



y_pred_dt[:5]

### Random Forest

from sklearn.ensemble import RandomForestRegressor
regressor_rf = RandomForestRegressor(n_estimators = 100, random_state = 0) 
regressor_rf.fit(X_train, y_train)

y_predict_rf = regressor_rf.predict(X_test)

# Metrics for Random Forest
MSE  = mean_squared_error((y_test)**2, (y_predict_rf)**2)
print("MSE :" , MSE)

RMSE = np.sqrt(MSE)
print("RMSE :" ,RMSE)

MAE= mean_absolute_error((y_test)**2,(y_predict_rf)**2)
print("MAE :" ,MAE)

r2 = r2_score((y_test)**2, (y_predict_rf)**2)
print("R2 :" ,r2)
print("Adjusted R2 : ",1-(1-r2_score((y_test)**2, (y_predict_rf)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))

linear regg
ridge_regg
lasso regg
elasticnet regg
dt
ran Forest

boosting bagging